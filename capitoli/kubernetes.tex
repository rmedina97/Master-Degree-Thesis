\chapter{Kubernetes}
(CITA https://kubernetes.io/docs/concepts/overview/  METTERLA COME CITAZIONE TRA VIRGOLETTE?)
Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation


Kubernetes emerged as a platform designed to automate the management of containerized applications, ensuring periodic checks to maintain alignment between the actual operational state and the defined ideal state through a declarative language. A decade since its release as an open-source project, Kubernetes stands as one of the most extensively utilized platforms worldwide. This project focuses on k3s, a lightweight variant of Kubernetes tailored for operation in resource-constrained environments.

\section{Basic concepts}
The foundational principles underlying the architecture of Kubernetes are articulated as follows:
\begin{enumerate}
\item Implementation-agnostic APIs: Each Kubernetes object can be implemented differently depending on the version being used, yet the interface used to manage these objects remains consistent across all versions.
\item Completely declarative specification: Kubernetes facilitates the use of a declarative language instead of the traditional imperative approach, simplifying application management by specifying the desired state directly rather than detailing how to achieve that state from various starting points.
\item Control loop-oriented approach: Kubernetes employs components known as controllers that cyclically monitor whether the current state aligns with the desired state. If discrepancies are identified, these controllers initiate actions to minimize the gap between the states.
\end{enumerate}
These principles are the cornerstone of Kubernetes, facilitating efficient management and orchestration of containerized applications in a variety of computing environments.

Every object within Kubernetes is meticulously crafted to adhere to foundational principles, starting with its smallest operational unit: the pod. A pod may consist of one or more containers and its configuration is defined in its respective YAML file. This file may reference other configuration files using key-value pairs, such as Secrets or ConfigMaps, useful in case these configurations are repeated multiple times. 
Pods are typically instantiated through the implementation of various Kubernetes controllers.

The Deployment controller, commonly used for stateless applications, describes the desired application state while managing scalability through the ReplicaSet. For stateful applications, the StatefulSet controller is normally utilized, managing the pod-to-volume binding and ensuring properties such as unique network IDs that the stateful application required to function properly.
While controllers oversee the lifecycle of pods, pod discovery is entrusted to Services. These Kubernetes objects target all pods matching their selector criteria, facilitating exposure both within and outside the cluster. ClusterIP services expose pods solely within the cluster, whereas NodePort or LoadBalancer services extend pod accessibility externally.
Pods are instantiated on physical or virtual machines known as nodes, which serve either as master or worker nodes based on their role. A master node not only executes various Kubernetes components, as previously discussed, but also hosts the cluster's control plane such as the scheduler, controller manager, and API server. Conversely, a worker node is dedicated solely to executing the workloads of Kubernetes objects.
The cluster, comprising these nodes, can be structured as a single-master or multi-master configuration. In a multi-master setup, control plane components are replicated across all master nodes, with decisions made via a consensus mechanism based on a quorum(CITA QUALCOSA?). This setup necessitates an odd number of master nodes to prevent split-brain(CITA WIKIPEDIA O RICERCA?) scenarios and reduce decision-making delays. These structural and operational principles form the backbone of Kubernetes architecture, facilitating scalable and efficient container orchestration in diverse computing environments.

\section{Multi-master station architecture}
The current state of research has advanced to managing a single station through a multi-master architecture (CITA SEBASTIANO TESI?), leveraging the resilience gained from the ability to withstand the failure of a master node, albeit at the cost of increased resources required for replicated control-plane components. While this approach is effective for managing a single station, it proves suboptimal when applied to an entire electrical control system. This is due to both the complexity involved in managing a large number of nodes (with stations alone numbering in the tens of thousands, whereas Kubernetes officially supports up to 5000 nodes (CITA DOCS?)) and the inability to function in isolation. In fact, if a segment of the network underlying a master node becomes isolated from the rest of the architecture, it becomes unmanageable as the master node loses the necessary consensus to initiate new workloads (new pods to manage the isolated entities) and can only partially manage existing workloads (because it can't reschedule workloads if it fails).
The only additional failure scenario that the translated architecture can address is when an entire secondary station becomes isolated from the network, allowing the PDC pod to be relocated to another station. However, this advantage does not outweigh the drawbacks in terms of complexity, scalability, and resource demands inherent in the overall architecture. These challenges can be effectively addressed by adopting Liqo technology.